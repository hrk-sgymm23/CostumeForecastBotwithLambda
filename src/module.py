import os
import random

import openai
import requests
from dotenv import load_dotenv

load_dotenv(verbose=True)
openai.api_key = os.environ.get("OPENAI_API_KEY")

def get_weather_info():
    try:
        response_info = requests.get(os.environ.get("API_ENDPOINT")).json()
        return response_info
    except requests.RequestException as e:
        print("å¤©æ°—æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ", e)

def parse_message(response_info):
    # å¤©æ°—æƒ…å ±(æ–‡é¢)
    text = response_info["description"]["text"]

    #  é™æ°´ç¢ºç‡ã€é¢¨å‘ãã€æœ€é«˜æœ€ä½æ°—æ¸©(ä¸‰æ—¥åˆ†ãŒé…åˆ—ã§å…¥ã£ã¦ã„ã‚‹)
    forecasts = response_info["forecasts"][0]
    # ç©ºæ¨¡æ§˜
    sky_appearance = forecasts["telop"]
    sky_appearance_detail = forecasts["detail"]["weather"]
    # æ°—æ¸©
    max_temp = forecasts["temperature"]["max"]["celsius"]
    min_temp = forecasts["temperature"]["min"]["celsius"]
    # é™æ°´ç¢ºç‡
    probability_rain_0to6 = forecasts["chanceOfRain"]["T00_06"]
    probability_rain_6to12 = forecasts["chanceOfRain"]["T06_12"]
    probability_rain_12to18 = forecasts["chanceOfRain"]["T12_18"]
    probability_rain_18to24 = forecasts["chanceOfRain"]["T18_24"]
    # fæ–‡å­—åˆ—ã‚’ä½¿ã£ã¦å„å€¤ã‚’åŸ‹ã‚è¾¼ã¿æ¬¡ã®é–¢æ•°ã¸æ¸¡ã™
    weather_message = f"""
    ## æœ¬æ—¥ã¨æ˜æ—¥ã®å¤©æ°—ã¨æ°—æ¸©ã®èª¬æ˜
    {text}

    ## ç©ºæ¨¡æ§˜
    {sky_appearance}
    ## ç©ºæ¨¡æ§˜ã®ç§»ã‚Šå¤‰ã‚ã‚Š
    {sky_appearance_detail}

    ## æœ€é«˜æ°—æ¸©
    {max_temp}
    ## æœ€ä½æ°—æ¸©
    {min_temp}

    ## 0æ™‚ã‹ã‚‰6æ™‚ã®é™æ°´ç¢ºç‡
    {probability_rain_0to6}
    ## 6æ™‚ã‹ã‚‰12æ™‚ã®é™æ°´ç¢ºç‡
    {probability_rain_6to12}
    ## 12æ™‚ã‹ã‚‰18æ™‚ã®é™æ°´ç¢ºç‡
    {probability_rain_12to18}
    ## 18æ™‚ã‹ã‚‰24æ™‚ã®é™æ°´ç¢ºç‡
    {probability_rain_18to24}

    ã‚ãªãŸã¯æ°—è±¡æƒ…å ±ã‹ã‚‰é©åˆ‡ãªæœè£…ã‚’å°ãå‡ºã™ãƒ—ãƒ­ã®æœè£…ã‚¢ãƒ‰ãƒã‚¤ã‚¶ãƒ¼ã§ã™ã€‚
    ä¸Šè¨˜ã®ãƒ†ã‚­ã‚¹ãƒˆç¾¤ã¯æœ¬æ—¥ã®æ°—è±¡æƒ…å ±ã‚’èª¬æ˜ã™ã‚‹ã‚‚ã®ã«ãªã‚Šã¾ã™ã€‚
    è¨˜è¼‰ã•ã‚Œã‚‹è¨˜è¼‰æƒ…å ±ã®çŠ¶æ³ã«é©ã—ãŸæœè£…ã‚’ä»¥ä¸‹ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¨æ³¨æ„äº‹é …ã«å¾“ã£ã¦å‡ºåŠ›ã—ãªã•ã„ã€‚

    <å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä¾‹>
    ğŸŒ¤ä»Šæ—¥ã®è¡£è£…äºˆå ±ã‚’ãŠå±Šã‘ï¼
    ä»Šæ—¥ã¯æœxxâ„ƒæ˜¼xxâ„ƒå¤œxxâ„ƒã¨ã€Œxxãªæ—¥ã€ã§ã™ã€‚
    æœã¯xxã‚„xx+xx/xx/xxãŒå¿…è¦ã§ã™ã€‚
    xxã‚„xxã§xxå¯¾ç­–ã‚’ï¼ä»Šæ—¥ã‚‚ç´ æ•µãª1æ—¥ã‚’ãŠéã”ã—ãã ã•ã„ï¼

    <æ³¨æ„äº‹é …>
    - 140å­—ä»¥å†…ã§å‡ºåŠ›ã—ã¦ãã ã•ã„
    - ä¸Šç€ãªã©ã¨ã„ã£ãŸæŠ½è±¡çš„ãªã‚‚ã®ã§ã¯ãªãã‚³ãƒ¼ãƒˆã‚„ãƒ€ã‚¦ãƒ³ã¨ã„ã£ãŸå…·ä½“çš„ãªã„ã‚‹ã®åå‰ã‚’ã‚ã’ã‚‹ã‚ˆã†ã«ã—ã¦ãã ã•ã„
    - æš‘ã„å ´åˆã¯ã“ã¾ã‚ãªæ°´åˆ†è£œçµ¦ã‚’ï¼å¯’ã„å ´åˆã¯å‡çµã«æ³¨æ„ï¼ãªã©æœè£…ã«é–¢ä¿‚ãªã„å ´åˆã‚‚å¿…è¦ã§ã‚ã‚Œã°å…¥ã‚Œã¦ãã ã•ã„
    """
    

    print(weather_message)

    return weather_message


def recommend_costume(weather_message):
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": weather_message},
        ],
    )
    recommend_costume_message = response["choices"][0]["message"]["content"]

    return recommend_costume_message

def choose_rails_article(recent_artilce: list[dict[str, str]]) -> list[dict[str, str]]:
    title_list = [article["title"] for article in recent_artilce]

    message = f"""
    RubyonRailsã«é–¢ã™ã‚‹è¨˜äº‹ã‚’ç´¹ä»‹ã™ã‚‹ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚
    ä»¥ä¸‹ã¯ã€Rubyã¨Ruby on railsã«é–¢ã™ã‚‹è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«ãƒªã‚¹ãƒˆã§ã™ã€‚
    ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã®è¦³ç‚¹ã‹ã‚‰ã€æ´»ç”¨æ–¹æ³•ã‚„å­¦ã³ã€tipsã‚’ã‚·ã‚§ã‚¢ã™ã‚‹è¨˜äº‹ã‚’é¸å®šã—ãªã•ã„ã€‚
    é¸å®šåŸºæº–ã¨ã€è¨˜äº‹ãƒªã‚¹ãƒˆã¯ä»¥ä¸‹ã§ã™ã€‚
    ã‚¢ã‚¦ãƒˆãƒ—ãƒƒãƒˆã¯ã€ãƒ†ã‚­ã‚¹ãƒˆã¯ä¸€åˆ‡ä¸è¦ã§ã€è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿è¿”ã—ã¦ãã ã•ã„ã€‚

    ã€é¸å®šåŸºæº–ã€‘
    ãƒ»Rubyã«é–¢ã™ã‚‹è¨˜äº‹ã¾ãŸã¯Ruby on railsã«é–¢ã™ã‚‹è¨˜äº‹

    ã€è¨˜äº‹ãƒªã‚¹ãƒˆã€‘
    {title_list}
    """
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "user", "content": message},
        ],
    )
    rails_article_title = response["choices"][0]["message"]["content"]

    rails_article = [
        article for article in recent_artilce if article["title"] in rails_article_title
    ]

    return rails_article[0]


def summary_tweet(rails_article: list[dict[str, str]]) -> str:
    personality = f"""
    ã‚ãªãŸã¯Rubyã¨Ruby on railsã®ãƒ—ãƒ­ã§ã™ã€‚
    æ¬¡ã®è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã«å¯¾ã—ã¦ã€ãƒ—ãƒ­ã®è¦³ç‚¹ã‹ã‚‰ã€æ´»ç”¨æ–¹æ³•ã‚„å­¦ã³ã‚’ã‚·ã‚§ã‚¢ã—ã¾ã™ã€‚
    
    å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã¯ä»¥ä¸‹ã§ã™ã€‚
    ã‚¿ã‚¤ãƒˆãƒ«ã®ã¿ãŒå‡ºåŠ›ã§ãã‚Œã°è‰¯ã„ã§ã™ã€‚
    èª¬æ˜æ–‡ç­‰ã¯å¿…è¦ã‚ã‚Šã¾ã›ã‚“ã€‚

    â€»æ³¨æ„äº‹é …
    è¿”ç­”ã¯140å­—ä»¥å†…ã§æ§‹æˆã—ã¦ãã ã•ã„ã€‚
    ç¹°ã‚Šè¿”ã—ã¾ã™140å­—ä»¥å†…ã§ãŠé¡˜ã„ã—ã¾ã™!!!!!!   

    ã€å›ç­”ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã€‘
    ğŸ›‘Ruby on Railsã®è¨˜äº‹ã‚’ç´¹ä»‹ğŸ›‘
    ğŸ—£ã€Œ[è¨˜äº‹ã®ã‚¿ã‚¤ãƒˆãƒ«å]ã€

    https://zenn.dev/neet/articles/{rails_article["slug"]}
    """
    response = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[
            {"role": "system", "content": personality},
            {"role": "user", "content": rails_article["title"]},
        ],
    )
    return response["choices"][0]["message"]["content"]